{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define in advance constants to build the model\n",
    "\n",
    "INPUT_SHAPE = (96, 96, 3)\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "FULL_SIZE = 160\n",
    "\n",
    "EPOCHS = 10\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "MODEL_PATH = \"./models/net_0_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read coordinates from files\n",
    "sealions_df_train = pd.read_csv('./sealions_train.csv', dtype={\"coord_x\": int, \"coord_y\": int, \"class\": str, \"filename\": str})\n",
    "sealions_df_test = pd.read_csv('./sealions_test.csv', dtype={\"coord_x\": int, \"coord_y\": int, \"class\": str, \"filename\": str})\n",
    "empty_df_train = pd.read_csv('./empty_train.csv', dtype={\"coord_x\": int, \"coord_y\": int, \"filename\": str})\n",
    "empty_df_test = pd.read_csv('./empty_test.csv', dtype={\"coord_x\": int, \"coord_y\": int, \"filename\": str})\n",
    "\n",
    "file_names_sea_lions_train = sealions_df_train.filename.unique()\n",
    "file_names_sea_lions_test = sealions_df_test.filename.unique()\n",
    "file_names_background_train = empty_df_train.filename.unique()\n",
    "file_names_background_test = empty_df_test.filename.unique()\n",
    "\n",
    "# Create global variable for data sets\n",
    "data_set_sea_lions_train = []\n",
    "data_set_sea_lions_test = []\n",
    "data_set_background_train = []\n",
    "data_set_background_test = []\n",
    "\n",
    "MAX_SIZE_TRAIN = 3000\n",
    "MAX_SIZE_TEST = 1000\n",
    "\n",
    "# Use a random seed\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and extract 96x96 patches for sea lions\n",
    "def extract_sea_lions(file_names, data_set, sea_lions_df, max_size):\n",
    "    for file in file_names:\n",
    "        image = cv2.imread(\"./kaggle_sea_lions/Train/\" + file)\n",
    "        df = sea_lions_df[sea_lions_df['filename'] == file]\n",
    "        for row in df.iterrows():\n",
    "            x = row[1]['coord_x']\n",
    "            y = row[1]['coord_y']\n",
    "            if x < 48:\n",
    "                x = 0\n",
    "            elif x > len(image[0]) - 48:\n",
    "                x = len(image[0]) - 96\n",
    "            else:\n",
    "                x = x - 48\n",
    "            if y < 48:\n",
    "                y = 0\n",
    "            elif y > len(image) - 48:\n",
    "                y = len(image) - 96\n",
    "            else:\n",
    "                y = y - 48\n",
    "            patch = image[y:y+96, x:x+96, :]\n",
    "            data_set.append(list((patch, \"sea lion\")))\n",
    "            if len(data_set) >= max_size:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and extract 96x96 patches for background\n",
    "def extract_background(file_names, data_set, empty_df, max_size):\n",
    "    for file in file_names:\n",
    "        image = cv2.imread(\"./kaggle_sea_lions/Train/\" + file)\n",
    "        df = empty_df[empty_df['filename'] == file]\n",
    "        for row in df.iterrows():\n",
    "            x = row[1]['coord_x']\n",
    "            y = row[1]['coord_y']\n",
    "            patch = image[y-48:y+48, x-48:x+48, :]\n",
    "            data_set.append(list((patch, \"background\")))\n",
    "            if len(data_set) >= max_size:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4) Failed to allocate 63078912 bytes in function cv::OutOfMemoryError\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-33c3641ee83a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract patches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mextract_sea_lions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_names_sea_lions_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_set_sea_lions_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msealions_df_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mextract_sea_lions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_names_sea_lions_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_set_sea_lions_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msealions_df_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mextract_background\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_names_background_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_set_background_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mempty_df_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mextract_background\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_names_background_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_set_background_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mempty_df_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-37f5c3c49ae0>\u001b[0m in \u001b[0;36mextract_sea_lions\u001b[1;34m(file_names, data_set, sea_lions_df)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_sea_lions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msea_lions_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./kaggle_sea_lions/Train/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msea_lions_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msea_lions_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4) Failed to allocate 63078912 bytes in function cv::OutOfMemoryError\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Extract patches\n",
    "extract_sea_lions(file_names_sea_lions_train, data_set_sea_lions_train, sealions_df_train, MAX_SIZE_TRAIN)\n",
    "extract_sea_lions(file_names_sea_lions_test, data_set_sea_lions_test, sealions_df_test, MAX_SIZE_TEST)\n",
    "extract_background(file_names_background_train, data_set_background_train, empty_df_train, MAX_SIZE_TRAIN)\n",
    "extract_background(file_names_background_test, data_set_background_test, empty_df_test, MAX_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train set\n",
    "train_set = data_set_sea_lions_train + data_set_background_train\n",
    "random.shuffle(train_set)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for data in train_set:\n",
    "    X_train.append(data[0])\n",
    "    if data[1] == \"sea lion\":\n",
    "        Y_train.append([1, 0])\n",
    "    elif data[1] == \"background\":\n",
    "        Y_train.append([0, 1])\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "# Build test set\n",
    "test_set = data_set_sea_lions_test + data_set_background_test\n",
    "random.shuffle(test_set)\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for data in test_set:\n",
    "    X_test.append(data[0])\n",
    "    if data[1] == \"sea lion\":\n",
    "        Y_test.append([1, 0])\n",
    "    elif data[1] == \"background\":\n",
    "        Y_test.append([0, 1])\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Convert data types and normalize values\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build parallel model (multi gpu)\n",
    "\n",
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Convolution2D(8, (5, 5), activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Third layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fourth layer\n",
    "model.add(Convolution2D(10, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "parallel_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test (multi gpu)\n",
    "\n",
    "# Fit model on training data\n",
    "parallel_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VALIDATION_SPLIT, verbose=1)\n",
    "\n",
    "# Evaluate model on test data\n",
    "loss_and_metrics = parallel_model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "# Save trained model (multi gpu)\n",
    "parallel_model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ROC and AUC\n",
    "\n",
    "Y_pred = parallel_model.predict_proba(X_test)\n",
    "\n",
    "roc_auc_score(Y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
