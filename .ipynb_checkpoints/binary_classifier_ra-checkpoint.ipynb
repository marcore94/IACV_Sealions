{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vincenzo\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import gc\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define in advance constants to build the model\n",
    "\n",
    "INPUT_SHAPE = (96, 96, 3)\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "OPTIMIZER = keras.optimizers.Adam()\n",
    "LOSS = 'binary_crossentropy'\n",
    "METRIC = 'accuracy'\n",
    "\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "MODEL_PATH = \"./binary_classifier/net_0_model.json\"\n",
    "WEIGHTS_PATH = \"./binary_classifier/net_0_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a random seed\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load patches for sea lions\n",
    "def extract_patches(path, size, label):\n",
    "    data_set = []\n",
    "    for file in range(0, size):\n",
    "        patch = cv2.imread(\"./patches/\" + path + \"/\" + str(file) + \".jpg\")\n",
    "        data_set.append(list((patch, label)))\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train patches\n",
    "data_set_sea_lions_train = extract_patches(\"sealions_train\", 62652, \"sea lion\")\n",
    "data_set_background_train = extract_patches(\"background_train\", 62652, \"background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train set\n",
    "train_set = data_set_sea_lions_train + data_set_background_train\n",
    "random.shuffle(train_set)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for data in train_set:\n",
    "    X_train.append(data[0])\n",
    "    if data[1] == \"sea lion\":\n",
    "        Y_train.append([1, 0])\n",
    "    elif data[1] == \"background\":\n",
    "        Y_train.append([0, 1])\n",
    "X_train = np.array(X_train, copy=False)\n",
    "Y_train = np.array(Y_train, copy=False)\n",
    "\n",
    "# Free memory\n",
    "data_set_sea_lions_train = []\n",
    "data_set_background_train = []\n",
    "train_set = []\n",
    "gc.collect()\n",
    "\n",
    "# Convert data types and normalize values\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build parallel model (multi gpu)\n",
    "\n",
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Convolution2D(8, (5, 5), activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Third layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fourth layer\n",
    "model.add(Convolution2D(10, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "parallel_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[METRIC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100243 samples, validate on 25061 samples\n",
      "Epoch 1/100\n",
      "100243/100243 [==============================] - 63s 628us/step - loss: 0.3090 - acc: 0.8731 - val_loss: 0.3076 - val_acc: 0.9028\n",
      "Epoch 2/100\n",
      "100243/100243 [==============================] - 64s 638us/step - loss: 0.2487 - acc: 0.9056 - val_loss: 0.3847 - val_acc: 0.8667\n",
      "Epoch 3/100\n",
      "100243/100243 [==============================] - 59s 585us/step - loss: 0.2304 - acc: 0.9156 - val_loss: 0.3514 - val_acc: 0.8366\n",
      "Epoch 4/100\n",
      "100243/100243 [==============================] - 63s 627us/step - loss: 0.2169 - acc: 0.9205 - val_loss: 0.2735 - val_acc: 0.8911\n",
      "Epoch 5/100\n",
      "100243/100243 [==============================] - 63s 626us/step - loss: 0.2120 - acc: 0.9230 - val_loss: 0.4133 - val_acc: 0.7774\n",
      "Epoch 6/100\n",
      "100243/100243 [==============================] - 63s 628us/step - loss: 0.2048 - acc: 0.9254 - val_loss: 0.3094 - val_acc: 0.8575\n",
      "Epoch 7/100\n",
      "100243/100243 [==============================] - 62s 622us/step - loss: 0.2042 - acc: 0.9257 - val_loss: 0.3059 - val_acc: 0.8558\n",
      "Epoch 8/100\n",
      "100243/100243 [==============================] - 62s 618us/step - loss: 0.1997 - acc: 0.9280 - val_loss: 0.2535 - val_acc: 0.8941\n",
      "Epoch 9/100\n",
      "100243/100243 [==============================] - 61s 607us/step - loss: 0.1967 - acc: 0.9295 - val_loss: 0.3082 - val_acc: 0.8520\n",
      "Epoch 10/100\n",
      "100243/100243 [==============================] - 61s 604us/step - loss: 0.1950 - acc: 0.9296 - val_loss: 0.2229 - val_acc: 0.9083\n",
      "Epoch 11/100\n",
      "100243/100243 [==============================] - 60s 601us/step - loss: 0.1953 - acc: 0.9298 - val_loss: 0.3237 - val_acc: 0.8348\n",
      "Epoch 12/100\n",
      "100243/100243 [==============================] - 60s 601us/step - loss: 0.1927 - acc: 0.9304 - val_loss: 0.2222 - val_acc: 0.9159\n",
      "Epoch 13/100\n",
      "100243/100243 [==============================] - 60s 602us/step - loss: 0.1906 - acc: 0.9309 - val_loss: 0.3287 - val_acc: 0.8321\n",
      "Epoch 14/100\n",
      "100243/100243 [==============================] - 60s 603us/step - loss: 0.1919 - acc: 0.9302 - val_loss: 0.2816 - val_acc: 0.8685\n",
      "Epoch 15/100\n",
      "100243/100243 [==============================] - 60s 601us/step - loss: 0.1891 - acc: 0.9312 - val_loss: 0.2591 - val_acc: 0.8870\n",
      "Epoch 16/100\n",
      "100243/100243 [==============================] - 61s 607us/step - loss: 0.1882 - acc: 0.9324 - val_loss: 0.3359 - val_acc: 0.8301\n",
      "Epoch 17/100\n",
      "100243/100243 [==============================] - 60s 601us/step - loss: 0.1876 - acc: 0.9327 - val_loss: 0.2335 - val_acc: 0.9046\n",
      "Epoch 18/100\n",
      "100243/100243 [==============================] - 60s 598us/step - loss: 0.1847 - acc: 0.9340 - val_loss: 0.3944 - val_acc: 0.7985\n",
      "Epoch 19/100\n",
      "100243/100243 [==============================] - 60s 599us/step - loss: 0.1841 - acc: 0.9338 - val_loss: 0.3107 - val_acc: 0.8531\n",
      "Epoch 20/100\n",
      "100243/100243 [==============================] - 60s 599us/step - loss: 0.1829 - acc: 0.9344 - val_loss: 0.3218 - val_acc: 0.8474\n",
      "Epoch 21/100\n",
      "100243/100243 [==============================] - 60s 597us/step - loss: 0.1848 - acc: 0.9340 - val_loss: 0.2949 - val_acc: 0.8657\n",
      "Epoch 22/100\n",
      "100243/100243 [==============================] - 60s 599us/step - loss: 0.1821 - acc: 0.9353 - val_loss: 0.2907 - val_acc: 0.8631\n",
      "Epoch 23/100\n",
      "100243/100243 [==============================] - 60s 598us/step - loss: 0.1814 - acc: 0.9344 - val_loss: 0.2546 - val_acc: 0.8883\n",
      "Epoch 24/100\n",
      "100243/100243 [==============================] - 60s 599us/step - loss: 0.1800 - acc: 0.9351 - val_loss: 0.2974 - val_acc: 0.8577\n",
      "Epoch 25/100\n",
      "100243/100243 [==============================] - 60s 601us/step - loss: 0.1811 - acc: 0.9362 - val_loss: 0.3280 - val_acc: 0.8447\n",
      "Epoch 26/100\n",
      "100243/100243 [==============================] - 60s 600us/step - loss: 0.1800 - acc: 0.9354 - val_loss: 0.3973 - val_acc: 0.7871\n",
      "Epoch 27/100\n",
      "100243/100243 [==============================] - 60s 603us/step - loss: 0.1803 - acc: 0.9358 - val_loss: 0.3668 - val_acc: 0.8104\n",
      "Epoch 28/100\n",
      "100243/100243 [==============================] - 60s 601us/step - loss: 0.1775 - acc: 0.9372 - val_loss: 0.2497 - val_acc: 0.8933\n",
      "Epoch 29/100\n",
      "100243/100243 [==============================] - 60s 595us/step - loss: 0.1778 - acc: 0.9360 - val_loss: 0.3232 - val_acc: 0.8401\n",
      "Epoch 30/100\n",
      "100243/100243 [==============================] - 61s 604us/step - loss: 0.1755 - acc: 0.9368 - val_loss: 0.3188 - val_acc: 0.8479\n",
      "Epoch 31/100\n",
      "100243/100243 [==============================] - 61s 605us/step - loss: 0.1775 - acc: 0.9366 - val_loss: 0.2522 - val_acc: 0.8899\n",
      "Epoch 32/100\n",
      "100243/100243 [==============================] - 60s 601us/step - loss: 0.1757 - acc: 0.9368 - val_loss: 0.2775 - val_acc: 0.8744\n",
      "Epoch 33/100\n",
      "100243/100243 [==============================] - 60s 602us/step - loss: 0.1772 - acc: 0.9366 - val_loss: 0.3268 - val_acc: 0.8348\n",
      "Epoch 34/100\n",
      "100243/100243 [==============================] - 61s 608us/step - loss: 0.1753 - acc: 0.9380 - val_loss: 0.3636 - val_acc: 0.8113\n",
      "Epoch 35/100\n",
      "100243/100243 [==============================] - 61s 604us/step - loss: 0.1762 - acc: 0.9369 - val_loss: 0.2810 - val_acc: 0.8717\n",
      "Epoch 36/100\n",
      "100243/100243 [==============================] - 60s 602us/step - loss: 0.1747 - acc: 0.9374 - val_loss: 0.2523 - val_acc: 0.8928\n",
      "Epoch 37/100\n",
      "100243/100243 [==============================] - 61s 610us/step - loss: 0.1746 - acc: 0.9383 - val_loss: 0.2419 - val_acc: 0.9014\n",
      "Epoch 38/100\n",
      "100243/100243 [==============================] - 62s 622us/step - loss: 0.1738 - acc: 0.9390 - val_loss: 0.2518 - val_acc: 0.8922\n",
      "Epoch 39/100\n",
      "100150/100243 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9377"
     ]
    }
   ],
   "source": [
    "# Train (multi gpu)\n",
    "\n",
    "# Fit model on training data\n",
    "history = parallel_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VALIDATION_SPLIT, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model (multi gpu)\n",
    "\n",
    "# serialize model to JSON\n",
    "# model_json = parallel_model.to_json()\n",
    "# with open(MODEL_PATH, \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "parallel_model.save_weights(WEIGHTS_PATH)\n",
    "\n",
    "# Free memory\n",
    "X_train = []\n",
    "Y_train = []\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test patches\n",
    "\n",
    "data_set_sea_lions_test = extract_patches(\"sealions_test\", 17634, \"sea lion\")\n",
    "data_set_background_test = extract_patches(\"background_test\", 17634, \"background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build test set\n",
    "test_set = data_set_sea_lions_test + data_set_background_test\n",
    "random.shuffle(test_set)\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for data in test_set:\n",
    "    X_test.append(data[0])\n",
    "    if data[1] == \"sea lion\":\n",
    "        Y_test.append([1, 0])\n",
    "    elif data[1] == \"background\":\n",
    "        Y_test.append([0, 1])\n",
    "X_test = np.array(X_test, copy=False)\n",
    "Y_test = np.array(Y_test, copy=False)\n",
    "\n",
    "# Free memory\n",
    "data_set_sea_lions_test = []\n",
    "data_set_background_test = []\n",
    "test_set = []\n",
    "gc.collect()\n",
    "\n",
    "# Convert data types and normalize values\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35268/35268 [==============================] - 10s 273us/step\n",
      "acc: 88.67%\n"
     ]
    }
   ],
   "source": [
    "# Test (multi gpu)\n",
    "\n",
    "# Evaluate model on test data\n",
    "loss_and_metrics = parallel_model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "print(\"%s: %.2f%%\" % (parallel_model.metrics_names[1], loss_and_metrics[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797711937301261"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate ROC and AUC\n",
    "\n",
    "Y_pred = parallel_model.predict(X_test)\n",
    "roc_auc_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "X_test = []\n",
    "Y_test = []\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
