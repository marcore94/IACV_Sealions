{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array,\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define in advance constants to build the model\n",
    "\n",
    "INPUT_SHAPE = (96, 96, 3)\n",
    "OUTPUT_SIZE = 2\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "OPTIMIZER = keras.optimizers.Adam()\n",
    "LOSS = 'binary_crossentropy'\n",
    "METRIC = 'accuracy'\n",
    "\n",
    "EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "MODEL_PATH = \"./binary_classifier/net_0_model.json\"\n",
    "WEIGHTS_PATH = \"./binary_classifier/net_0_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(file_name, epoch_act, epoch_tot, batch_size):\n",
    "    csv_file = open(file_name)\n",
    "    reader = csv.reader(csv_file)\n",
    "    batch_count = 0\n",
    "    patched_images = []\n",
    "    for line in reader:\n",
    "        patches = []\n",
    "        classes = []\n",
    "        image_name = line[3]                    # line[3] is path to image\n",
    "        if image_name not in patched_images:    #open image only if not opened yet\n",
    "            patched_images.append(image_name)\n",
    "            image = cv2.imread(image_name) \n",
    "        if line[2] == \"background\":\n",
    "            patches.append(extract_background_patch(image, line[0], line[1]))\n",
    "            classes.append(\"background\")    \n",
    "        elif line[2] == \"sea lion\":\n",
    "            patches.append(extract_sea_lion_patch(image, line[0], line[1], epoch_act, epoch_tot))\n",
    "            classes.append(\"sea lion\")\n",
    "        batch_count += 1\n",
    "        if batch_count >= batch_size:\n",
    "            batch_count = 0\n",
    "            x = np.array(patches)\n",
    "            y = np.array(classes)\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build parallel model (multi gpu)\n",
    "\n",
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Convolution2D(8, (5, 5), activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# Second layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# Third layer\n",
    "model.add(Convolution2D(5, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# Fourth layer\n",
    "model.add(Convolution2D(10, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(OUTPUT_SIZE, activation='softmax'))\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "parallel_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[METRIC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generation of augmented datasets\n",
    "#augmented training dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=360, #range for random rotations\n",
    "    #width_shift_range=,#float of range for random hor. shifts\n",
    "    #height_shift_range=,#float of range for random ver. shifts\n",
    "    horizontal_flip=1,  #random hor.flip\n",
    "    vertical_flip=1, #random ver. flip\n",
    "    #rescale=\n",
    ")\n",
    "\n",
    "#not augmented testing dataset\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "#not augmented validation dataset\n",
    "validation_dataset = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method needs a directory with training data and another one with validation ones\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit_generator(\n",
    "#        train_generator,\n",
    "        #steps_per_epoch= // batch_size, #n. of samples of dataset divided by the batch size\n",
    "#        epochs=50,\n",
    "#        validation_data=validation_generator,\n",
    "#        validation_steps=800 // batch_size)\n",
    "#model.save_weights('weights.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator for augmented images\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    # Define rotation range between 0 and 360 degrees\n",
    "    rotation_range=360,\n",
    "    # Define range of random horizontal shifts (expressed as fraction of total width)\n",
    "    width_shift_range=0.2,\n",
    "    # Define range of random vertical shifts (expressed as fraction of total height)\n",
    "    height_shift_range=0.2,\n",
    "    # Define shear intensity\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background patches extractor\n",
    "def extract_background_patch(image, coord_x, coord_y):\n",
    "    patch = image[coord_y-48:coord_y+48, coord_x-48:coord_x+48, :]\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sea lions patches extractor\n",
    "def extract_sea_lion_patch(image, coord_x, coord_y, epoch, n_epochs):\n",
    "    if coord_x < 72:\n",
    "        coord_x = 0\n",
    "    elif coord_x > len(image[0]) - 72:\n",
    "        coord_x = len(image[0]) - 144\n",
    "    else:\n",
    "        coord_x = coord_x - 72\n",
    "    if coord_y < 72:\n",
    "        coord_y = 0\n",
    "    elif coord_y > len(image) - 72:\n",
    "        coord_y = len(image) - 144\n",
    "    else:\n",
    "        coord_y = coord_y - 72\n",
    "    external_patch = image[coord_y:coord_y+144, coord_x:coord_x+144, :]\n",
    "    if rand.uniform(0.0, 1.0) < (epoch/n_epochs):\n",
    "        # Perform transformation\n",
    "        for aug_img in datagen.flow(img_to_array(external_patch), [1, 0]):\n",
    "            external_patch = array_to_img(aug_img)\n",
    "            break\n",
    "    patch = external_patch[72-48:72+48, 72-48:72+48, :]\n",
    "    return patch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
